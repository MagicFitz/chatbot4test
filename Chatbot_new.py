import openai
import streamlit as st
import requests
import json

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate

# åˆå§‹åŒ–Streamlitåº”ç”¨
st.title("ğŸ’¬ è—æ ¼çŸ¿ä¸šçŸ¥è¯†é—®ç­”")
st.caption("å›ç­”å…³äºè—æ ¼çŸ¿ä¸šå„ç§è§„ç« åˆ¶åº¦çš„é—®é¢˜")
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

# åŠ è½½å‘é‡åº“æ–‡ä»¶
embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')
new_db = FAISS.load_local('./', embeddings)

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    # è®¾ç½®OpenAI APIå¯†é’¥
    openai.api_base = 'https://api.openai-proxy.org/v1'
    openai.api_key = 'sk-yE9AUncq99czee9GsytQYP4QxYuZal44kPMx5y9rkqojGVu3'

    # ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
    user_message = {"role": "user", "content": prompt}

    # è·å–åŒ¹é…çš„å‘é‡æ–‡æ¡£
    docs = new_db.similarity_search(prompt)
    content = ''.join(doc['page_content'] for doc in docs)

    # æ„å»ºå¯¹è¯æ¶ˆæ¯
    system_message_prompt = SystemMessagePromptTemplate.from_template(content)
    human_template = "```{docs}```\n<{question}>"
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    msg = chat_prompt.format_prompt(docs=content, question=prompt)

    st.session_state.messages.append(user_message)
    st.chat_message("user").write(prompt)

    # ä½¿ç”¨OpenAI GPT-3ç”Ÿæˆå›å¤
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=st.session_state.messages)
    assistant_msg = response.choices[0].message
    st.session_state.messages.append(assistant_msg)
    st.chat_message("assistant").write(assistant_msg.content)
